{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0356b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, torch, torch.nn as nn, pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob, os, timeit\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46118df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de47ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('megasequence-to-cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19605d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>Cancer type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sample_0025</td>\n",
       "      <td>NNNTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sample_0026</td>\n",
       "      <td>NNNTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sample_0027</td>\n",
       "      <td>AACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACC...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sample_0028</td>\n",
       "      <td>CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sample_0029</td>\n",
       "      <td>NNNTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample ID                                           sequence Cancer type\n",
       "0  Sample_0025  NNNTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...      Normal\n",
       "1  Sample_0026  NNNTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...      Normal\n",
       "2  Sample_0027  AACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACC...      Normal\n",
       "3  Sample_0028  CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...      Normal\n",
       "4  Sample_0029  NNNTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...      Normal"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "859c08b8",
   "metadata": {
    "id": "41Ks2b8EbQX_"
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10deb1fa",
   "metadata": {
    "id": "nrq6O_UoaNn9"
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "np.get_include() # do we need this on colab? \n",
    "cimport cython\n",
    "cimport numpy as np\n",
    "\n",
    "# Adding Z here so we can encode the separator\n",
    "cdef dict bases={ 'A':<int>0, 'C':<int>1, 'G':<int>2, 'T':<int>3, 'Z':<int>4} \n",
    "\n",
    "@cython.boundscheck(False)\n",
    "def one_hot( str string ):\n",
    "    cdef np.ndarray[np.float32_t, ndim=2] res = np.zeros( (5,len(string)), dtype=np.float32 )\n",
    "    cdef int j\n",
    "    for j in range(len(string)):\n",
    "        if string[j] in bases: # bases can be 'N' signifying missing: this corresponds to all 0 in the encoding\n",
    "            res[ bases[ string[j] ], j ]=float(1.0)\n",
    "    return(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb55af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = pickle.load(open('hg19.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dfc652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff8d42d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80imMbLs0Wxx",
    "outputId": "25540ca0-0659-4f73-cb0e-c65b98057e41"
   },
   "outputs": [],
   "source": [
    "# In the first step we will split the data in training and remaining dataset\n",
    "data_train, data_rem = train_test_split(all_data, train_size=0.8, random_state=543)\n",
    "\n",
    "# Now since we want the valid and test size to be equal (10% each of overall data). \n",
    "# we have to define valid_size=0.5 (that is 50% of remaining data)\n",
    "test_size = 0.5\n",
    "data_validation, data_test = train_test_split(data_rem, test_size=0.5, random_state=82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbf6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da6fb932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_222240/943087518.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stuff['size'] = stuff['sequence'].apply(lambda row: len(row))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.610000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.614851e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.231679e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.181000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.239024e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.354215e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.348382e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.384835e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               size\n",
       "count  3.610000e+02\n",
       "mean   1.614851e+07\n",
       "std    1.231679e+07\n",
       "min    8.181000e+03\n",
       "25%    6.239024e+06\n",
       "50%    1.354215e+07\n",
       "75%    2.348382e+07\n",
       "max    9.384835e+07"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff = data_train\n",
    "stuff['size'] = stuff['sequence'].apply(lambda row: len(row))\n",
    "stuff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c82aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb1f95f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-b1YTY4rvLiQ",
    "outputId": "8f165cbe-0e47-4c64-d932-7d480f840bd1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample ID</th>\n",
       "      <th>sequence</th>\n",
       "      <th>Cancer type</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Sample_0243</td>\n",
       "      <td>CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>7219593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Sample_0893</td>\n",
       "      <td>CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Leukemia</td>\n",
       "      <td>62366209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Sample_0544</td>\n",
       "      <td>CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Leukemia</td>\n",
       "      <td>43331138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Sample_1171</td>\n",
       "      <td>ACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCC...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>15393051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Sample_0832</td>\n",
       "      <td>CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>The Yellow fever</td>\n",
       "      <td>4825374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Sample_1255</td>\n",
       "      <td>CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>4743539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Sample_0302</td>\n",
       "      <td>CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>29292305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sample_0219</td>\n",
       "      <td>CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>25674355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Sample_0273</td>\n",
       "      <td>CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>10586725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Sample_0825</td>\n",
       "      <td>CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...</td>\n",
       "      <td>The Yellow fever</td>\n",
       "      <td>2762849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sample ID                                           sequence  \\\n",
       "73   Sample_0243  CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...   \n",
       "289  Sample_0893  CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...   \n",
       "196  Sample_0544  CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...   \n",
       "316  Sample_1171  ACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCC...   \n",
       "256  Sample_0832  CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...   \n",
       "..           ...                                                ...   \n",
       "361  Sample_1255  CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...   \n",
       "132  Sample_0302  CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...   \n",
       "49   Sample_0219  CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...   \n",
       "103  Sample_0273  CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...   \n",
       "249  Sample_0825  CCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCT...   \n",
       "\n",
       "          Cancer type      size  \n",
       "73             Normal   7219593  \n",
       "289          Leukemia  62366209  \n",
       "196          Leukemia  43331138  \n",
       "316            Normal  15393051  \n",
       "256  The Yellow fever   4825374  \n",
       "..                ...       ...  \n",
       "361            Normal   4743539  \n",
       "132            Normal  29292305  \n",
       "49             Normal  25674355  \n",
       "103            Normal  10586725  \n",
       "249  The Yellow fever   2762849  \n",
       "\n",
       "[361 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for chip-seq data: also shuffling nucleotides can be done to keep the GC content the same as positive example\n",
    "# because sequencing has biases with GC content and this would be a way to \"fix it\"\n",
    "class BedPeaksDataset(torch.utils.data.IterableDataset):\n",
    "\n",
    "    def __init__(self, data_set):\n",
    "        super(BedPeaksDataset, self).__init__()\n",
    "        self.atac_data = data_set\n",
    "\n",
    "    def __iter__(self): \n",
    "        for i,row in enumerate(self.atac_data.itertuples()):\n",
    "            seq = row.sequence\n",
    "            value = np.float32(1)\n",
    "            print(row)\n",
    "            if row._3 == \"Normal\":\n",
    "                value = np.float32(0)\n",
    "            yield(one_hot(seq), value) # positive example\n",
    "\n",
    "train_dataset = BedPeaksDataset(data_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1000, num_workers = 0)\n",
    "\n",
    "#validation_dataset = BedPeaksDataset(data_validation)\n",
    "#validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=1000, num_workers=0)\n",
    "\n",
    "#test_dataset = BedPeaksDataset(data_test)\n",
    "#test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, num_workers=0)\n",
    "\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c10d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fee2db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_epoch(train_flag, dataloader, model, optimizer, device=\"cuda\"):\n",
    "\n",
    "    torch.set_grad_enabled(train_flag)\n",
    "    model.train() if train_flag else model.eval() \n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for (x,y) in dataloader: # collection of tuples with iterator\n",
    "\n",
    "        (x, y) = ( x.to(device), y.to(device) ) # transfer data to GPU\n",
    "        print('a')\n",
    "\n",
    "        output = model(x) # forward pass\n",
    "        print('b')\n",
    "        output = output.squeeze(1) # remove spurious channel dimension\n",
    "        print('c')\n",
    "        loss = F.binary_cross_entropy_with_logits( output, y ) # numerically stable\n",
    "        print('d')\n",
    "\n",
    "        if train_flag: \n",
    "            loss.backward() # back propagation\n",
    "            print('e')\n",
    "            optimizer.step()\n",
    "            print('f')\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print('g')\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        accuracy = torch.mean( ( (output > .5) == (y > .5) ).float() )\n",
    "        accuracies.append(accuracy.detach().cpu().numpy())\n",
    "        print(losses[-1], accuracies[-1])\n",
    "    \n",
    "    return( np.mean(losses), np.mean(accuracies) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a622e2fd",
   "metadata": {
    "id": "mhDEJy1-iphQ"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_data, validation_data, epochs=100, patience=10, batch_size=1000, verbose = True):\n",
    "    \"\"\"\n",
    "    Train a 1D CNN model and record accuracy metrics.\n",
    "    \"\"\"\n",
    "    # Move the model to the GPU here to make it runs there, and set \"device\" as above\n",
    "    # TODO CODE\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # 1. Make new BedPeakDataset and DataLoader objects for both training and validation data.\n",
    "    # TODO CODE\n",
    "    train_dataset = BedPeaksDataset(train_data)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers = 3, timeout=600)\n",
    "    validation_dataset = BedPeaksDataset(validation_data)\n",
    "    validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, num_workers = 3, timeout=600)\n",
    "\n",
    "    # 2. Instantiates an optimizer for the model. \n",
    "    # TODO CODE\n",
    "    optimizer = torch.optim.Adam(model.parameters(), amsgrad=True)\n",
    "\n",
    "    # 3. Run the training loop with early stopping. \n",
    "    # TODO CODE\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    patience_counter = patience\n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    \n",
    "    # Get a list of all the file paths that ends with .txt from in specified directory\n",
    "    fileList = glob.glob('./checkpoints/model_checkpoint*.pt')\n",
    "    # Iterate over the list of filepaths & remove each file.\n",
    "    for filePath in fileList:\n",
    "        try:\n",
    "            os.remove(filePath)\n",
    "        except:\n",
    "            print(\"Error while deleting file : \", filePath)\n",
    "    \n",
    "    \n",
    "    check_point_filename = './checkpoints/model_checkpoint.pt' # to save the best model fit to date\n",
    "    local_min_counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        start_time = timeit.default_timer()\n",
    "        train_loss, train_acc = run_one_epoch(True, train_dataloader, model, optimizer, device)\n",
    "        val_loss, val_acc = run_one_epoch(False, validation_dataloader, model, optimizer, device)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        if val_loss < best_val_loss: \n",
    "            if patience_counter < patience:\n",
    "                local_min_counter = local_min_counter + 1\n",
    "            torch.save(model.state_dict(), f'./checkpoints/model_checkpoint-{local_min_counter}.pt')\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = patience\n",
    "        else: \n",
    "            patience_counter -= 1\n",
    "            if patience_counter <= 0: \n",
    "                model.load_state_dict(torch.load(f'./checkpoints/model_checkpoint-{local_min_counter}.pt')) # recover the best model so far\n",
    "                break\n",
    "        elapsed = float(timeit.default_timer() - start_time)\n",
    "        print(\"Epoch %i took %.2fs. Train loss: %.4f acc: %.4f. Val loss: %.4f acc: %.4f. Patience left: %i\" % \n",
    "              (epoch+1, elapsed, train_loss, train_acc, val_loss, val_acc, patience_counter ))\n",
    "\n",
    "    # 4. Return the fitted model (not strictly necessary since this happens \"in place\"), train and validation accuracies.\n",
    "    # TODO CODE\n",
    "    return model, train_accs, val_accs, train_losses, val_losses, validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d080391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04617256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e821f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 n_output_channels = 1, \n",
    "                 n_hidden = 32, \n",
    "                 dropout = 0.2,\n",
    "                 n_fc = 1,\n",
    "                 lstm_hidden=10):\n",
    "        \n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.Sequential(nn.GRU(5, lstm_hidden, batch_first=True, dropout=dropout))\n",
    "        \n",
    "        fc_layers = [nn.Linear(lstm_hidden, n_hidden)]\n",
    "        for i in range(n_fc-1):\n",
    "            fc_layers += [ nn.Dropout(dropout),\n",
    "                          nn.ELU(inplace=True),\n",
    "                          nn.Linear(n_hidden, n_hidden)\n",
    "            ]\n",
    "        fc_layers += [nn.Dropout(dropout),\n",
    "                      nn.ELU(inplace=True),\n",
    "                      nn.Linear(n_hidden, n_output_channels)\n",
    "        ]\n",
    "        self.dense_net = nn.Sequential(*fc_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(x.size())\n",
    "        # switch sequence and channels and send to LSTM\n",
    "        #net, (hn, cn) = self.lstm(x.swapaxes(1, 2))\n",
    "        net, hn = self.lstm(x.swapaxes(1, 2))\n",
    "        #print(net.size())\n",
    "        net = net[:, -1, :]\n",
    "        #print(net.size())\n",
    "        net = net.view(net.size(0), -1)\n",
    "        #print(net.size())\n",
    "        net = self.dense_net(net)\n",
    "        print(net.size())\n",
    "        return(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c1ba50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.28 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([1, 1])\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "0.7352559 1.0\n",
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([1, 1])\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "0.75025254 1.0\n",
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([1, 1])\n",
      "b\n",
      "c\n",
      "d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "e\n",
      "f\n",
      "g\n",
      "0.71687573 1.0\n",
      "a\n",
      "torch.Size([1, 1])\n",
      "b\n",
      "c\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "lstm_model = LSTM(dropout=.28, n_hidden=32, n_fc=2, lstm_hidden=2)\n",
    "\n",
    "lstm_model, train_accs, val_accs, train_losses, val_losses, lstm_validation_datloader = train_model(lstm_model, data_train\n",
    "                                                                         , data_validation, epochs=300\n",
    "                                                                         , patience=20, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb67910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8292e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6c877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
